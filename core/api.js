/**
 * Easy Prompt â€” API è°ƒç”¨å±‚
 * å¹³å°æ— å…³çš„ HTTP è¯·æ±‚å°è£…ï¼Œä½¿ç”¨ curl é¿å… Cloudflare æ‹¦æˆª
 * æ”¯æŒ 4 ç§ API æ¨¡å¼ï¼šopenai / openai-responses / claude / gemini
 */

const { spawn } = require("child_process");
const { platform } = require("os");

// è¾“å…¥é•¿åº¦é™åˆ¶ï¼ˆ10000 å­—ç¬¦ï¼‰
const MAX_INPUT_LENGTH = 10000;

// API æ¨¡å¼å¸¸é‡
const API_MODES = {
  OPENAI: "openai",
  OPENAI_RESPONSES: "openai-responses",
  CLAUDE: "claude",
  GEMINI: "gemini",
};

// æ¯ç§æ¨¡å¼çš„é»˜è®¤ API è·¯å¾„
const DEFAULT_API_PATHS = {
  [API_MODES.OPENAI]: "/v1/chat/completions",
  [API_MODES.OPENAI_RESPONSES]: "/v1/responses",
  [API_MODES.CLAUDE]: "/v1/messages",
  [API_MODES.GEMINI]: "/v1beta",
};

/**
 * ä» baseUrl è‡ªåŠ¨æ¨æ–­ API æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
 * ä»…å½“ config ä¸­ç¼ºå°‘ apiMode æ—¶ä½¿ç”¨
 */
function detectApiMode(baseUrl) {
  if (!baseUrl) return API_MODES.OPENAI;
  const normalized = baseUrl.replace(/\/+$/, "").toLowerCase();
  if (normalized.endsWith("/responses")) return API_MODES.OPENAI_RESPONSES;
  if (
    normalized.includes("anthropic") ||
    normalized.includes("/v1/messages") ||
    normalized.endsWith("/messages")
  )
    return API_MODES.CLAUDE;
  if (
    normalized.includes("generativelanguage.googleapis.com") ||
    normalized.includes("/v1beta") ||
    normalized.includes("/v1alpha")
  )
    return API_MODES.GEMINI;
  return API_MODES.OPENAI;
}

// é‡è¯•é…ç½®
const MAX_RETRIES = 3;
const RETRY_DELAYS = [2000, 4000, 8000]; // æŒ‡æ•°é€€é¿ï¼š2s, 4s, 8s

// curl å¯ç”¨æ€§ç¼“å­˜ï¼ˆé¿å…æ¯æ¬¡è°ƒç”¨éƒ½ spawn è¿›ç¨‹æ£€æŸ¥ï¼‰
let _curlAvailable = null;

/**
 * æ£€æŸ¥ curl æ˜¯å¦å¯ç”¨ï¼ˆå¸¦ç¼“å­˜ï¼‰
 */
function checkCurl() {
  if (_curlAvailable !== null) return Promise.resolve(_curlAvailable);
  return new Promise((resolve) => {
    const proc = spawn(platform() === "win32" ? "where" : "which", ["curl"]);
    proc.on("close", (code) => {
      _curlAvailable = code === 0;
      resolve(_curlAvailable);
    });
    proc.on("error", () => {
      _curlAvailable = false;
      resolve(false);
    });
  });
}

/**
 * åˆ¤æ–­é”™è¯¯æ˜¯å¦å€¼å¾—é‡è¯•
 */
function isRetryableError(error) {
  const msg = error.message || "";
  const retryablePatterns = [
    "cpu overloaded",
    "overloaded",
    "503",
    "529",
    "502",
    "Bad Gateway",
    "Service Unavailable",
    "temporarily unavailable",
    "server_error",
    "internal_error",
    "ECONNRESET",
    "ETIMEDOUT",
    "socket hang up",
    "Connection reset",
    "è¯·æ±‚è¶…æ—¶",
    "Rate limit",
    "rate_limit",
    "429",
    "Too Many Requests",
  ];
  return retryablePatterns.some((p) =>
    msg.toLowerCase().includes(p.toLowerCase()),
  );
}

/**
 * å‹å¥½åŒ–é”™è¯¯æ¶ˆæ¯ â€” å°†æŠ€æœ¯é”™è¯¯è½¬æ¢ä¸ºç”¨æˆ·å¯ç†è§£çš„ä¸­æ–‡æç¤º
 */
function friendlyError(errorMsg, model) {
  const msg = errorMsg.toLowerCase();

  // === æœåŠ¡ç«¯è¿‡è½½/ä¸å¯ç”¨ ===
  if (msg.includes("cpu overloaded") || msg.includes("overloaded")) {
    return "âš¡ API æœåŠ¡å™¨ç¹å¿™ï¼ˆCPU è¿‡è½½ï¼‰Â· å½“å‰ä½¿ç”¨äººæ•°è¿‡å¤šï¼Œè¯·ç­‰å¾… 10-30 ç§’åé‡è¯•";
  }
  if (
    msg.includes("503") ||
    msg.includes("service unavailable") ||
    msg.includes("temporarily unavailable")
  ) {
    return "ğŸ”§ API æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼ˆ503ï¼‰Â· æœåŠ¡å™¨ç»´æŠ¤æˆ–ä¸´æ—¶æ•…éšœï¼Œè¯·ç­‰å¾…å‡ åˆ†é’Ÿåé‡è¯•";
  }
  if (msg.includes("502") || msg.includes("bad gateway")) {
    return "ğŸŒ API ç½‘å…³é”™è¯¯ï¼ˆ502ï¼‰Â· ä¸­è½¬æœåŠ¡å™¨è¿æ¥é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•";
  }
  if (msg.includes("529")) {
    return "ğŸ”¥ API æœåŠ¡å™¨è¿‡è½½ï¼ˆ529ï¼‰Â· è¯·æ±‚é‡è¿‡å¤§ï¼Œè¯·ç­‰å¾… 30 ç§’åé‡è¯•";
  }
  if (
    msg.includes("server_error") ||
    msg.includes("internal_error") ||
    msg.includes("500") ||
    msg.includes("internal server error")
  ) {
    return "ğŸ› ï¸ API æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ Â· æœåŠ¡ç«¯ä¸´æ—¶æ•…éšœï¼Œè¯·ç¨åé‡è¯•";
  }

  // === è®¤è¯/æˆæƒé”™è¯¯ ===
  if (
    msg.includes("401") ||
    msg.includes("unauthorized") ||
    msg.includes("incorrect api key") ||
    msg.includes("invalid api key") ||
    msg.includes("authentication")
  ) {
    return "ğŸ”‘ API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ Â· è¯·åœ¨è®¾ç½®ä¸­æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®";
  }
  if (msg.includes("403") || msg.includes("forbidden")) {
    return "ğŸš« API è®¿é—®è¢«æ‹’ç»ï¼ˆ403ï¼‰Â· Key æƒé™ä¸è¶³æˆ– IP è¢«é™åˆ¶ï¼Œè¯·æ£€æŸ¥é…ç½®";
  }

  // === é¢‘ç‡é™åˆ¶ ===
  if (
    msg.includes("429") ||
    msg.includes("rate limit") ||
    msg.includes("too many requests")
  ) {
    return "â³ API è¯·æ±‚é¢‘ç‡è¶…é™ï¼ˆ429ï¼‰Â· è¯·ç­‰å¾… 30-60 ç§’åé‡è¯•";
  }

  // === æ¨¡å‹é”™è¯¯ ===
  if (
    msg.includes("model") &&
    (msg.includes("does not exist") ||
      msg.includes("not found") ||
      msg.includes("not available"))
  ) {
    return `ğŸ¤– æ¨¡å‹ "${model}" ä¸å¯ç”¨ Â· è¯·åœ¨è®¾ç½®ä¸­æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®`;
  }

  // === é¢åº¦/é…é¢ ===
  if (
    msg.includes("quota") ||
    msg.includes("insufficient") ||
    msg.includes("billing") ||
    msg.includes("payment")
  ) {
    // å°è¯•ä»é”™è¯¯æ¶ˆæ¯ä¸­æå–é‡‘é¢ä¿¡æ¯ï¼ˆå¦‚ "remain quota: $0.014000, need quota: $0.096000"ï¼‰
    const remainMatch = errorMsg.match(/remain[^$]*\$([0-9.]+)/i);
    const needMatch = errorMsg.match(/need[^$]*\$([0-9.]+)/i);
    if (remainMatch && needMatch) {
      const remain = parseFloat(remainMatch[1]).toFixed(2);
      const need = parseFloat(needMatch[1]).toFixed(2);
      return `ğŸ’° API é¢åº¦ä¸è¶³ï¼ˆå‰©ä½™ $${remain}ï¼Œéœ€è¦ $${need}ï¼‰Â· è¯·åœ¨è®¾ç½®ä¸­é…ç½®æ‚¨è‡ªå·±çš„ API Keyï¼Œæˆ–ä¸ºå½“å‰ Key å……å€¼`;
    }
    return "ğŸ’° API é¢åº¦ä¸è¶³ Â· è¯·åœ¨è®¾ç½®ä¸­é…ç½®æ‚¨è‡ªå·±çš„ API Keyï¼Œæˆ–æ£€æŸ¥å½“å‰è´¦æˆ·ä½™é¢";
  }

  // === ç½‘ç»œè¿æ¥é—®é¢˜ ===
  if (
    msg.includes("could not resolve host") ||
    msg.includes("getaddrinfo") ||
    msg.includes("dns")
  ) {
    return "ğŸŒ æ— æ³•è¿æ¥åˆ° API æœåŠ¡å™¨ Â· è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ VPN/ä»£ç†è®¾ç½®";
  }
  if (msg.includes("connection refused") || msg.includes("econnrefused")) {
    return "ğŸ”Œ è¿æ¥è¢«æ‹’ç» Â· è¯·æ£€æŸ¥ API Base URL æ˜¯å¦æ­£ç¡®";
  }
  if (
    msg.includes("timeout") ||
    msg.includes("timed out") ||
    msg.includes("etimedout") ||
    msg.includes("è¯·æ±‚è¶…æ—¶")
  ) {
    return "â±ï¸ API è¯·æ±‚è¶…æ—¶ Â· è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–ç¼©çŸ­è¾“å…¥æ–‡æœ¬åé‡è¯•";
  }
  if (
    msg.includes("econnreset") ||
    msg.includes("connection reset") ||
    msg.includes("socket hang up")
  ) {
    return "ğŸ”„ è¿æ¥è¢«é‡ç½® Â· ç½‘ç»œä¸ç¨³å®šï¼Œè¯·ç¨åé‡è¯•";
  }
  if (
    msg.includes("ssl") ||
    msg.includes("certificate") ||
    msg.includes("cert")
  ) {
    return "ğŸ”’ SSL/TLS è¯ä¹¦é”™è¯¯ Â· è¯·æ£€æŸ¥ç³»ç»Ÿæ—¶é—´å’Œä»£ç†è¯ä¹¦é…ç½®";
  }

  // === curl ç›¸å…³ ===
  if (msg.includes("curl") && msg.includes("not found")) {
    return "ğŸ”§ æœªæ‰¾åˆ° curl å‘½ä»¤ Â· macOS/Linux é€šå¸¸é¢„è£…ï¼ŒWindows è¯·å®‰è£… Git for Windows";
  }

  // === å“åº”è§£æé”™è¯¯ ===
  if (msg.includes("è§£æå“åº”å¤±è´¥") || msg.includes("json")) {
    return "ğŸ“‹ API è¿”å›æ ¼å¼é”™è¯¯ Â· è¯·æ£€æŸ¥ Base URL æ˜¯å¦æ­£ç¡®";
  }

  // === è¾“å…¥ç›¸å…³ ===
  if (msg.includes("è¿‡é•¿") || msg.includes("too long") || msg.includes("max")) {
    return `ğŸ“ è¾“å…¥æ–‡æœ¬è¿‡é•¿ Â· æœ€å¤§æ”¯æŒ ${MAX_INPUT_LENGTH} å­—ç¬¦ï¼Œè¯·ç¼©çŸ­åé‡è¯•`;
  }
  if (msg.includes("è¿”å›ä¸ºç©º") || msg.includes("empty")) {
    return "ğŸ“­ API è¿”å›ç»“æœä¸ºç©º Â· è¯·ä¿®æ”¹è¾“å…¥å†…å®¹åé‡è¯•";
  }

  // === å…œåº• ===
  return `âŒ API è°ƒç”¨å‡ºé”™: ${errorMsg} Â· è¯·æ£€æŸ¥ç½‘ç»œå’Œ API é…ç½®åé‡è¯•`;
}

/**
 * å»¶æ—¶ç­‰å¾…
 */
function delay(ms) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

/**
 * æ‰§è¡Œå•æ¬¡ API è°ƒç”¨ï¼ˆæ— é‡è¯•ï¼‰
 * æ”¯æŒ 4 ç§ API æ¨¡å¼ï¼šopenai / openai-responses / claude / gemini
 */
function callApiOnce(config, systemPrompt, userMessage, options = {}) {
  const { baseUrl, apiKey, model } = config;
  const apiMode = config.apiMode || detectApiMode(baseUrl);
  const { temperature = 0.7, maxTokens = 4096, timeout = 60 } = options;

  // å®‰å…¨é™åˆ¶ï¼šå“åº”ä½“æœ€å¤§ 2MBï¼Œé˜²æ­¢æ¶æ„æœåŠ¡å™¨è¿”å›å·¨å¤§å“åº”å¯¼è‡´ OOM
  const MAX_RESPONSE_SIZE = 2 * 1024 * 1024;

  const normalizedBase = baseUrl.replace(/\/+$/, "");

  // === æŒ‰æ¨¡å¼æ„å»ºè¯·æ±‚ URL ===
  let url;
  if (apiMode === API_MODES.GEMINI) {
    // Gemini: æ¨¡å‹ååµŒå…¥ URL è·¯å¾„ï¼ŒAPI Key æ”¾ query å‚æ•°
    url = `${normalizedBase}/models/${encodeURIComponent(model)}:generateContent?key=${encodeURIComponent(apiKey)}`;
  } else if (apiMode === API_MODES.OPENAI_RESPONSES) {
    url = normalizedBase.endsWith("/responses")
      ? normalizedBase
      : `${normalizedBase}/responses`;
  } else if (apiMode === API_MODES.CLAUDE) {
    url = normalizedBase.endsWith("/messages")
      ? normalizedBase
      : `${normalizedBase}/messages`;
  } else {
    // openaiï¼ˆé»˜è®¤ï¼‰
    url = normalizedBase.endsWith("/chat/completions")
      ? normalizedBase
      : `${normalizedBase}/chat/completions`;
  }

  // === æŒ‰æ¨¡å¼æ„å»ºè¯·æ±‚ä½“ ===
  let body;
  if (apiMode === API_MODES.GEMINI) {
    // Gemini API æ ¼å¼
    const payload = {
      contents: [
        {
          role: "user",
          parts: [{ text: userMessage }],
        },
      ],
      generationConfig: {
        temperature,
        maxOutputTokens: maxTokens,
      },
    };
    // Gemini çš„ system prompt ä½¿ç”¨ systemInstruction å­—æ®µ
    if (systemPrompt) {
      payload.systemInstruction = { parts: [{ text: systemPrompt }] };
    }
    body = JSON.stringify(payload);
  } else if (apiMode === API_MODES.CLAUDE) {
    // Claude API æ ¼å¼ï¼šsystem æ˜¯é¡¶çº§å­—æ®µï¼Œä¸åœ¨ messages ä¸­
    body = JSON.stringify({
      model,
      system: systemPrompt,
      messages: [{ role: "user", content: userMessage }],
      temperature,
      max_tokens: maxTokens,
    });
  } else if (apiMode === API_MODES.OPENAI_RESPONSES) {
    // OpenAI Responses API æ ¼å¼
    body = JSON.stringify({
      model,
      instructions: systemPrompt,
      input: userMessage,
      temperature,
      max_output_tokens: maxTokens,
    });
  } else {
    // OpenAI Chat Completions æ ¼å¼ï¼ˆé»˜è®¤ï¼‰
    body = JSON.stringify({
      model,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userMessage },
      ],
      temperature,
      max_tokens: maxTokens,
    });
  }

  // === æŒ‰æ¨¡å¼æ„å»º curl å‚æ•° ===
  const args = [
    "-s",
    "-S",
    "--max-time",
    String(timeout),
    "-X",
    "POST",
    url,
    "-H",
    "Content-Type: application/json",
  ];

  // æŒ‰æ¨¡å¼æ·»åŠ è®¤è¯å¤´
  if (apiMode === API_MODES.CLAUDE) {
    args.push("-H", `x-api-key: ${apiKey}`);
    args.push("-H", "anthropic-version: 2023-06-01");
  } else if (apiMode === API_MODES.GEMINI) {
    // Gemini: API Key å·²åœ¨ URL query å‚æ•°ä¸­ï¼Œæ— éœ€è®¤è¯å¤´
  } else {
    // OpenAI / OpenAI Responses: Bearer token
    args.push("-H", `Authorization: Bearer ${apiKey}`);
  }

  args.push("-d", "@-");

  return new Promise((resolve, reject) => {
    const curl = spawn("curl", args, {
      stdio: ["pipe", "pipe", "pipe"],
    });

    let stdout = "";
    let stderr = "";
    let stdoutSize = 0;
    let killed = false;

    // å®‰å…¨ä¿æŠ¤ï¼šè¶…æ—¶å¼ºåˆ¶ç»ˆæ­¢ curl è¿›ç¨‹ï¼ˆæ¯” curl è‡ªå·±çš„ --max-time å¤šç»™ 10s å®¹é”™ï¼‰
    const killTimer = setTimeout(
      () => {
        killed = true;
        curl.kill("SIGKILL");
      },
      (timeout + 10) * 1000,
    );

    curl.stdout.on("data", (data) => {
      stdoutSize += data.length;
      if (stdoutSize > MAX_RESPONSE_SIZE) {
        killed = true;
        curl.kill("SIGKILL");
        return;
      }
      stdout += data.toString();
    });

    curl.stderr.on("data", (data) => {
      stderr += data.toString();
    });

    curl.on("error", (err) => {
      clearTimeout(killTimer);
      reject(new Error(`curl æ‰§è¡Œå¤±è´¥: ${err.message}`));
    });

    curl.on("close", (code) => {
      clearTimeout(killTimer);

      if (killed && stdoutSize > MAX_RESPONSE_SIZE) {
        reject(new Error("å“åº”ä½“è¿‡å¤§ï¼ˆè¶…è¿‡ 2MBï¼‰ï¼Œå·²ä¸­æ–­è¿æ¥"));
        return;
      }
      if (killed) {
        reject(new Error("è¯·æ±‚è¶…æ—¶"));
        return;
      }

      if (code !== 0) {
        const errMsg = stderr || "æœªçŸ¥é”™è¯¯";
        reject(new Error(errMsg));
        return;
      }

      try {
        const resp = JSON.parse(stdout);

        // === æŒ‰æ¨¡å¼æ£€æŸ¥é”™è¯¯å“åº” ===
        if (resp.error) {
          const errorMsg = resp.error.message || JSON.stringify(resp.error);
          reject(new Error(errorMsg));
          return;
        }

        // === æŒ‰æ¨¡å¼è§£æå“åº” ===
        let content;
        if (apiMode === API_MODES.GEMINI) {
          // Gemini å“åº”æ ¼å¼
          content = resp.candidates?.[0]?.content?.parts?.[0]?.text;
        } else if (apiMode === API_MODES.CLAUDE) {
          // Claude å“åº”æ ¼å¼
          content = resp.content?.[0]?.text;
        } else if (apiMode === API_MODES.OPENAI_RESPONSES) {
          // OpenAI Responses API æ ¼å¼ï¼ˆé˜²å¾¡ resp.output éæ•°ç»„ï¼‰
          const outputArr = Array.isArray(resp.output) ? resp.output : [];
          const msgOutput = outputArr.find((o) => o.type === "message");
          const contentArr = Array.isArray(msgOutput?.content)
            ? msgOutput.content
            : [];
          content = contentArr.find((c) => c.type === "output_text")?.text;
        } else {
          // OpenAI Chat Completions æ ¼å¼
          content = resp.choices?.[0]?.message?.content;
        }

        if (!content) {
          reject(new Error("è¿”å›ä¸ºç©º"));
          return;
        }
        resolve(content);
      } catch (e) {
        reject(new Error(`è§£æå“åº”å¤±è´¥: ${e.message}`));
      }
    });

    curl.stdin.write(body);
    curl.stdin.end();
  });
}

/**
 * è°ƒç”¨ OpenAI å…¼å®¹ APIï¼ˆå¸¦è‡ªåŠ¨é‡è¯•ï¼‰
 * @param {Object} config - {baseUrl, apiKey, model}
 * @param {string} systemPrompt - ç³»ç»Ÿ Prompt
 * @param {string} userMessage - ç”¨æˆ·è¾“å…¥
 * @param {Object} [options] - {temperature, maxTokens, timeout, onRetry}
 * @returns {Promise<string>} AI è¿”å›çš„æ–‡æœ¬
 */
async function callApi(config, systemPrompt, userMessage, options = {}) {
  const { onRetry, ...callOptions } = options;

  // è¾“å…¥é•¿åº¦éªŒè¯
  if (userMessage.length > MAX_INPUT_LENGTH) {
    throw new Error(
      friendlyError(`è¾“å…¥æ–‡æœ¬è¿‡é•¿ï¼ˆ${userMessage.length} å­—ç¬¦ï¼‰`, config.model),
    );
  }

  // æ£€æŸ¥ curl æ˜¯å¦å¯ç”¨
  const hasCurl = await checkCurl();
  if (!hasCurl) {
    throw new Error(friendlyError("curl not found", config.model));
  }

  let lastError;
  for (let attempt = 0; attempt <= MAX_RETRIES; attempt++) {
    try {
      return await callApiOnce(config, systemPrompt, userMessage, callOptions);
    } catch (err) {
      lastError = err;

      // å¦‚æœæ˜¯ä¸å€¼å¾—é‡è¯•çš„é”™è¯¯ï¼ˆè®¤è¯é”™è¯¯ã€æ¨¡å‹ä¸å­˜åœ¨ç­‰ï¼‰ï¼Œç›´æ¥æŠ›å‡ºå‹å¥½æ¶ˆæ¯
      if (!isRetryableError(err) || attempt >= MAX_RETRIES) {
        throw new Error(friendlyError(err.message, config.model));
      }

      // ç­‰å¾…åé‡è¯•
      const delayMs = RETRY_DELAYS[attempt] || 8000;
      if (onRetry) {
        onRetry(attempt + 1, MAX_RETRIES, delayMs);
      }
      await delay(delayMs);
    }
  }

  // æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒåŒ…è£…ä¸ºå‹å¥½æ¶ˆæ¯æŠ›å‡º
  throw new Error(friendlyError(lastError.message, config.model));
}

/**
 * ä¸¤æ­¥è·¯ç”±ï¼šç¬¬ä¸€æ­¥æ„å›¾è¯†åˆ«ï¼ˆå¿«é€Ÿä½æ¸©ï¼‰ï¼Œç¬¬äºŒæ­¥ç”Ÿæˆï¼ˆæ­£å¸¸æ¸©åº¦ï¼‰
 */
async function callRouterApi(config, systemPrompt, userMessage, onRetry) {
  return callApi(config, systemPrompt, userMessage, {
    temperature: 0.1,
    maxTokens: 500,
    timeout: 30,
    onRetry,
  });
}

async function callGenerationApi(
  config,
  systemPrompt,
  userMessage,
  isComposite = false,
  onRetry,
) {
  return callApi(config, systemPrompt, userMessage, {
    temperature: 0.7,
    maxTokens: isComposite ? 8192 : 4096,
    timeout: 120,
    onRetry,
  });
}

module.exports = {
  callApi,
  callRouterApi,
  callGenerationApi,
  testApiConfig,
  fetchModels,
  API_MODES,
  DEFAULT_API_PATHS,
  detectApiMode,
};

/**
 * è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
 * æŒ‰ API æ¨¡å¼è‡ªåŠ¨é€‰æ‹©æ­£ç¡®çš„ç«¯ç‚¹å’Œè§£æé€»è¾‘
 * @param {Object} config - {baseUrl, apiKey, model, apiMode} (baseUrl = apiHost + apiPath)
 * @param {string} [apiHost] - API ä¸»æœºåœ°å€ï¼ˆå¯é€‰ï¼Œä¸æä¾›æ—¶ä» baseUrl æ¨å¯¼ï¼‰
 * @returns {Promise<{ok: boolean, models: string[], message: string}>}
 */
async function fetchModels(config, apiHost) {
  const apiMode = config.apiMode || detectApiMode(config.baseUrl);
  const baseUrl = (config.baseUrl || "").replace(/\/+$/, "");
  const apiKey = config.apiKey || "";

  // æ¨å¯¼ apiHostï¼šä¼˜å…ˆä½¿ç”¨ä¼ å…¥å€¼ï¼Œå¦åˆ™ä» baseUrl æå–åè®®+ä¸»æœº
  let host = apiHost;
  if (!host) {
    try {
      const u = new URL(baseUrl);
      host = u.origin; // e.g., https://api.openai.com
    } catch {
      return { ok: false, models: [], message: "æ— æ³•è§£æ API Host" };
    }
  }
  host = host.replace(/\/+$/, "");

  // æ¨å¯¼ç‰ˆæœ¬å‰ç¼€ï¼ˆä» apiPath æå–ï¼‰
  let versionPrefix;
  try {
    const u = new URL(baseUrl);
    const pathSegments = u.pathname.split("/").filter(Boolean);
    // ç‰ˆæœ¬å‰ç¼€é€šå¸¸æ˜¯ç¬¬ä¸€ä¸ªè·¯å¾„æ®µï¼ˆå¦‚ /v1, /v1betaï¼‰
    versionPrefix = pathSegments.length > 0 ? `/${pathSegments[0]}` : "/v1";
  } catch {
    versionPrefix = "/v1";
  }

  // === æŒ‰æ¨¡å¼æ„å»ºæ¨¡å‹åˆ—è¡¨è¯·æ±‚ ===
  let modelsUrl;
  const headers = ["-H", "Content-Type: application/json"];

  if (apiMode === API_MODES.GEMINI) {
    modelsUrl = `${host}${versionPrefix}/models?key=${encodeURIComponent(apiKey)}`;
    // Gemini: API Key åœ¨ URL ä¸­ï¼Œæ— éœ€è®¤è¯å¤´
  } else if (apiMode === API_MODES.CLAUDE) {
    modelsUrl = `${host}${versionPrefix}/models`;
    headers.push("-H", `x-api-key: ${apiKey}`);
    headers.push("-H", "anthropic-version: 2023-06-01");
  } else {
    // openai / openai-responses
    modelsUrl = `${host}${versionPrefix}/models`;
    headers.push("-H", `Authorization: Bearer ${apiKey}`);
  }

  // å®‰å…¨é™åˆ¶ï¼šæ¨¡å‹åˆ—è¡¨å“åº”ä½“æœ€å¤§ 2MB
  const MAX_RESPONSE_SIZE = 2 * 1024 * 1024;

  return new Promise((resolve) => {
    const args = ["-s", "-S", "--max-time", "15", modelsUrl, ...headers];

    const curl = spawn("curl", args, { stdio: ["pipe", "pipe", "pipe"] });
    let stdout = "";
    let stderr = "";
    let stdoutSize = 0;
    let killed = false;

    // å®‰å…¨ä¿æŠ¤ï¼šKill Timerï¼ˆæ¯” curl --max-time å¤š 10s å®¹é”™ï¼‰
    const killTimer = setTimeout(() => {
      killed = true;
      curl.kill("SIGKILL");
    }, 25 * 1000);

    curl.stdout.on("data", (data) => {
      stdoutSize += data.length;
      if (stdoutSize > MAX_RESPONSE_SIZE) {
        killed = true;
        curl.kill("SIGKILL");
        return;
      }
      stdout += data.toString();
    });
    curl.stderr.on("data", (data) => {
      stderr += data.toString();
    });

    curl.on("error", (err) => {
      clearTimeout(killTimer);
      resolve({
        ok: false,
        models: [],
        message: `è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: ${err.message}`,
      });
    });

    curl.on("close", (code) => {
      clearTimeout(killTimer);

      if (killed && stdoutSize > MAX_RESPONSE_SIZE) {
        resolve({
          ok: false,
          models: [],
          message: "æ¨¡å‹åˆ—è¡¨å“åº”ä½“è¿‡å¤§ï¼ˆè¶…è¿‡ 2MBï¼‰ï¼Œå·²ä¸­æ–­",
        });
        return;
      }
      if (killed) {
        resolve({
          ok: false,
          models: [],
          message: "è·å–æ¨¡å‹åˆ—è¡¨è¯·æ±‚è¶…æ—¶",
        });
        return;
      }

      if (code !== 0) {
        resolve({
          ok: false,
          models: [],
          message: `è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: ${stderr || "æœªçŸ¥é”™è¯¯"}`,
        });
        return;
      }

      try {
        const resp = JSON.parse(stdout);

        if (resp.error) {
          const errMsg = resp.error.message || JSON.stringify(resp.error);
          resolve({ ok: false, models: [], message: errMsg });
          return;
        }

        let models = [];
        if (apiMode === API_MODES.GEMINI) {
          // Gemini: models[].name å½¢å¦‚ "models/gemini-pro" â†’ å‰¥ç¦» "models/" å‰ç¼€
          models = (resp.models || [])
            .map((m) => (m.name || "").replace(/^models\//, ""))
            .filter(Boolean)
            .sort();
        } else {
          // OpenAI / Responses / Claude: data[].id
          models = (resp.data || [])
            .map((m) => m.id || "")
            .filter(Boolean)
            .sort();
        }

        if (models.length === 0) {
          resolve({ ok: false, models: [], message: "æœªè·å–åˆ°å¯ç”¨æ¨¡å‹" });
          return;
        }

        resolve({
          ok: true,
          models,
          message: `è·å–åˆ° ${models.length} ä¸ªæ¨¡å‹`,
        });
      } catch (e) {
        resolve({
          ok: false,
          models: [],
          message: `è§£ææ¨¡å‹åˆ—è¡¨å¤±è´¥: ${e.message}`,
        });
      }
    });
  });
}

/**
 * è½»é‡çº§ API é…ç½®æµ‹è¯•
 * å‘é€ä¸€ä¸ªæç®€è¯·æ±‚éªŒè¯è¿é€šæ€§ï¼ˆmaxTokens=5, æä½å¼€é”€ï¼‰
 * @param {Object} config - {baseUrl, apiKey, model, apiMode}
 * @returns {Promise<{ok: boolean, message: string, latency: number}>}
 */
async function testApiConfig(config) {
  const start = Date.now();
  try {
    // æ ¼å¼æ ¡éªŒï¼ˆå…ˆè§„èŒƒåŒ–å°¾éƒ¨æ–œæ ï¼‰
    const baseUrl = (config.baseUrl || "").replace(/\/+$/, "");
    if (!baseUrl || !baseUrl.match(/^https?:\/\//)) {
      return {
        ok: false,
        message: "API Host æ ¼å¼é”™è¯¯ï¼šå¿…é¡»ä»¥ http:// æˆ– https:// å¼€å¤´",
        latency: 0,
      };
    }
    if (!config.apiKey || !config.apiKey.trim()) {
      return { ok: false, message: "API Key ä¸èƒ½ä¸ºç©º", latency: 0 };
    }
    if (!config.model || !config.model.trim()) {
      return { ok: false, message: "æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º", latency: 0 };
    }

    // å‘é€æç®€è¯·æ±‚ï¼ˆcallApiOnce å†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç† apiModeï¼‰
    const result = await callApiOnce(config, "Reply with OK", "test", {
      temperature: 0,
      maxTokens: 5,
      timeout: 15,
    });

    const latency = Date.now() - start;
    return { ok: true, message: `è¿æ¥æˆåŠŸ Â· å“åº”è€—æ—¶ ${latency}ms`, latency };
  } catch (err) {
    const latency = Date.now() - start;
    return {
      ok: false,
      message: friendlyError(err.message, config.model),
      latency,
    };
  }
}
